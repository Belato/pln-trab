{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe4b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pre_processing import PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c16b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A inteligência artificial está transformando o mund0, com n0vas aplicações; Algoritmos de aprendizado de máquina sã0 essenciais para isso; A automação robótica é um dos camp0s mais interessantes da tecnologia hoje em-dia; O! processamento de8linguagem natural (PLN) permite que computadores compre+endam a linguagem humana; Chatbots e assistentes de voz sã0 um bom exemplo do PLN em ação.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da35847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\midiacom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "pre_processing = PreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b474f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pre_processing.lower_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5298a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pre_processing.split_in_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf28f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A inteligência artificial está transformando o mund0, com n0vas aplicações',\n",
       " 'Algoritmos de aprendizado de máquina sã0 essenciais para isso',\n",
       " 'A automação robótica é um dos camp0s mais interessantes da tecnologia hoje em-dia',\n",
       " 'O! processamento de8linguagem natural (PLN) permite que computadores compre+endam a linguagem humana',\n",
       " 'Chatbots e assistentes de voz sã0 um bom exemplo do PLN em ação.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a633b7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m new_tokens = \u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "for sentence in text:\n",
    "    format_text=[]\n",
    "    for t in sentence:\n",
    "        if '-' in t:\n",
    "            new_tokens = t.split('-')\n",
    "        print(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe07dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A inteligência artificial transformando mund0, n0vas aplicações',\n",
       " 'Algoritmos aprendizado máquina sã0 essenciais',\n",
       " 'A automação robótica camp0s interessantes tecnologia hoje em-dia',\n",
       " 'O! processamento de8linguagem natural (PLN) permite computadores compre+endam linguagem humana',\n",
       " 'Chatbots assistentes voz sã0 bom exemplo PLN ação.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in text:\n",
    "    text[text.index(sentence)] = pre_processing.remove_stop_words(sentence)\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c020ffb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A',\n",
       "  'inteligência',\n",
       "  'artificial',\n",
       "  'transformando',\n",
       "  'mund0',\n",
       "  ',',\n",
       "  'n0vas',\n",
       "  'aplicações'],\n",
       " ['Algoritmos', 'aprendizado', 'máquina', 'sã0', 'essenciais'],\n",
       " ['A',\n",
       "  'automação',\n",
       "  'robótica',\n",
       "  'camp0s',\n",
       "  'interessantes',\n",
       "  'tecnologia',\n",
       "  'hoje',\n",
       "  'em-dia'],\n",
       " ['O',\n",
       "  '!',\n",
       "  'processamento',\n",
       "  'de8linguagem',\n",
       "  'natural',\n",
       "  '(',\n",
       "  'PLN',\n",
       "  ')',\n",
       "  'permite',\n",
       "  'computadores',\n",
       "  'compre+endam',\n",
       "  'linguagem',\n",
       "  'humana'],\n",
       " ['Chatbots',\n",
       "  'assistentes',\n",
       "  'voz',\n",
       "  'sã0',\n",
       "  'bom',\n",
       "  'exemplo',\n",
       "  'PLN',\n",
       "  'ação',\n",
       "  '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in text:\n",
    "    text[text.index(sentence)] = pre_processing.tokenization(sentence)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea1cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['inteligência',\n",
       "  'artificial',\n",
       "  'transformando',\n",
       "  'mund0',\n",
       "  'n0vas',\n",
       "  'aplicações'],\n",
       " ['algoritmos', 'aprendizado', 'máquina', 'sã0', 'essenciais'],\n",
       " ['automação',\n",
       "  'robótica',\n",
       "  'camp0s',\n",
       "  'interessantes',\n",
       "  'tecnologia',\n",
       "  'hoje',\n",
       "  'emdia'],\n",
       " ['o',\n",
       "  'processamento',\n",
       "  'de8linguagem',\n",
       "  'natural',\n",
       "  'pln',\n",
       "  'permite',\n",
       "  'computadores',\n",
       "  'compreendam',\n",
       "  'linguagem',\n",
       "  'humana'],\n",
       " ['chatbots', 'assistentes', 'voz', 'sã0', 'bom', 'exemplo', 'pln', 'ação']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "for sentence in text:\n",
    "    # formatted_text = []\n",
    "    # for word in sentence:\n",
    "    #     format_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    #     if format_word:\n",
    "    #         formatted_text.append(format_word)\n",
    "    text[text.index(sentence)] = pre_processing.remove_special_characters(sentence)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4555967",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in text:\n",
    "\n",
    "    text[text.index(sentence)] = pre_processing.correct_words(sentence)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bee18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['intelig', 'artific', 'transform', 'mund0', 'n0v', 'aplic'],\n",
       " ['algoritm', 'aprend', 'máquin', 'sã0', 'essenc'],\n",
       " ['autom', 'robó', 'camp0', 'interess', 'tecnolog', 'hoj', 'emd'],\n",
       " ['o',\n",
       "  'process',\n",
       "  'de8lingu',\n",
       "  'natur',\n",
       "  'pln',\n",
       "  'permit',\n",
       "  'comput',\n",
       "  'compreend',\n",
       "  'lingu',\n",
       "  'human'],\n",
       " ['chatbot', 'assist', 'voz', 'sã0', 'bom', 'exempl', 'pln', 'açã']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in text:\n",
    "\n",
    "    text[text.index(sentence)] = pre_processing.stemizer(sentence)\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
